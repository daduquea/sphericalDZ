{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, 'utils/')\n",
    "\n",
    "from projection import Projection\n",
    "from projection_old import Projection as Proj_old\n",
    "from projection_old import *\n",
    "from utils_challenge import *\n",
    "from utils_projections import *\n",
    "from np_ioueval import iouEval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we take as input the 2D prediction presented in the previous notebook (2) Prediction of spherical projection). It is loaded in cell 4. The output of this notebook is a fully labeled 3D point cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_set = 'train'\n",
    "file_name = '40'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original downloaded data\n",
    "path_to_gt = 'input_data/point_clouds/' + selected_set\n",
    "path_to_dict = 'input_data/parameters/'\n",
    "\n",
    "\n",
    "path_to_ground_labeled = 'output_data/ground_labeled/'\n",
    "path_to_2d_preds = 'output_data/2d_preds/'\n",
    "output_path_3d = 'output_data/3d_preds/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = load_h5_file(path_to_2d_preds + file_name + '.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "width_sph = 1024\n",
    "height_sph = 64\n",
    "fov_up = 50\n",
    "fov_down = 115\n",
    "\n",
    "proj_sph = Proj_old(proj_type='front', width=width_sph, height=height_sph, fov_up=fov_up, fov_down=fov_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spherical_prediction(path_to_file, file_name):\n",
    "    full_path = os.path.join(path_to_file, file_name + '.npy')\n",
    "    return np.load(full_path)\n",
    "\n",
    "def load_point_cloud(path_to_file, file_name, skip_names = False):\n",
    "    full_path = os.path.join(path_to_file, file_name + '.txt')\n",
    "    if skip_names:\n",
    "        point_cloud = np.loadtxt(full_path, skiprows=1)\n",
    "    else:\n",
    "        point_cloud = np.loadtxt(full_path)\n",
    "    return point_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_centered_point_cloud(points):\n",
    "    min_val = points.min(0)\n",
    "\n",
    "    xmin = min_val[0]\n",
    "    ymin = min_val[1]\n",
    "    zmin = min_val[2]\n",
    "\n",
    "    centered_xyz = np.zeros_like(points)\n",
    "    centered_xyz[:,0] = points[:, 0] - xmin\n",
    "    centered_xyz[:,1] = points[:, 1] - ymin\n",
    "    centered_xyz[:,2] = points[:, 2]    \n",
    "    \n",
    "    return centered_xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_files = {\n",
    "    # training set\n",
    "\"00\": \"5D4KVPBP\",\n",
    "\"01\": \"5D4KVPC9\",\n",
    "\"02\": \"5D4KVPDO\",\n",
    "\"03\": \"5D4KVPFI\",\n",
    "\"04\": \"5D4KVPJE\",\n",
    "\"05\": \"5D4KVPNC\",\n",
    "\"06\": \"5D4KVPT5\",\n",
    "\"07\": \"5D4KVPX2\",\n",
    "\"08\": \"5D4KVQ0P\",\n",
    "\"09\": \"5D4KVRER\",\n",
    "\"10\": \"5D4KVRWC\",\n",
    "\"11\": \"5D4KVT48\",\n",
    "\"12\": \"5D4KVT9X\",\n",
    "\"13\": \"5D4KX2ZN\",\n",
    "\"14\": \"5D4KX3LW\",\n",
    "\"15\": \"5D4KX3PZ\",\n",
    "\"16\": \"5D4KX3VN\",\n",
    "\"17\": \"5D4KX4HE\",\n",
    "\"18\": \"5D4KX4QC\",\n",
    "\"19\": \"5D4KX4ZE\",\n",
    "\"20\": \"5D4KX56H\",\n",
    "\"21\": \"5D4KX5NM\",\n",
    "\"22\": \"5D4KX5WV\",\n",
    "\"23\": \"5D4KX66R\",\n",
    "\"24\": \"5D4KX6L3\",\n",
    "\"25\": \"5D4KX6T5\",\n",
    "\"26\": \"5D4KX7FN\",\n",
    "\"27\": \"5D4KX7IA\",\n",
    "\"28\": \"5D4KX7KT\",\n",
    "\"29\": \"5D4KX7RD\",\n",
    "\"30\": \"5D4KX826\",\n",
    "\"31\": \"5D4KX8IR\",\n",
    "\"32\": \"5D4KX8UQ\",\n",
    "\"33\": \"5D4KX8Y6\",\n",
    "\"34\": \"5D4KX993\",\n",
    "\"35\": \"5D4KX9SY\",\n",
    "\"36\": \"5D4KX9ZE\",\n",
    "\"37\": \"5D4KXA0G\",\n",
    "\"38\": \"5D4KXAW7\",\n",
    "\"39\": \"5D4KXB8D\",\n",
    "\"40\": \"5D4KXBC8\",\n",
    "\"41\": \"5D4KXBTC\",\n",
    "\"42\": \"5D4L1GZR\",\n",
    "\"43\": \"5D4L1IQ4\",\n",
    "\"44\": \"5D4L1M3I\",\n",
    "\"45\": \"5D4L1QP2\",\n",
    "\"46\": \"5D4L1RDR\",\n",
    "\"47\": \"5D4L1TH9\",\n",
    "\"48\": \"5D4L1TYC\",\n",
    "\"49\": \"5D4L1WHI\",\n",
    "\"50\": \"5D4L1XPJ\",\n",
    "\"51\": \"5D4L1Y38\",\n",
    "\"52\": \"5D4L1YDX\",\n",
    "\"53\": \"5D4L2BFI\",\n",
    "\"54\": \"5D4L2C9B\",\n",
    "\"55\": \"5D4L2DGW\",\n",
    "\"56\": \"5D4L2DTM\",\n",
    "\"57\": \"5D4L2FRJ\",\n",
    "\"58\": \"5D4L2G9K\",\n",
    "\"59\": \"5D4LHQUX\",\n",
    "    #test set\n",
    "\"60\": \"5D4KVPG4\",\n",
    "\"61\": \"5D4KVPIN\",\n",
    "\"62\": \"5D4KVPXD\",\n",
    "\"63\": \"5D4KVPYD\",\n",
    "\"64\": \"5D4KVQ9U\",\n",
    "\"65\": \"5D4KX38L\",\n",
    "\"66\": \"5D4KX3EC\",\n",
    "\"67\": \"5D4KX3RR\",\n",
    "\"68\": \"5D4KX3TQ\",\n",
    "\"69\": \"5D4KX40Y\",\n",
    "\"70\": \"5D4KX5G9\",\n",
    "\"71\": \"5D4KX76F\",\n",
    "\"72\": \"5D4KX9N2\",\n",
    "\"73\": \"5D4KX9SD\",\n",
    "\"74\": \"5D4L1JIE\",\n",
    "\"75\": \"5D4L1MGO\",\n",
    "\"76\": \"5D4L1P8E\",\n",
    "\"77\": \"5D4L1RW5\",\n",
    "\"78\": \"5D4L1TDI\",\n",
    "\"79\": \"5D4L1TX7\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading point cloud: 40\n",
      "loading ground detected with lambda flat zones\n"
     ]
    }
   ],
   "source": [
    "dict_name = os.path.join(path_to_dict, selected_set + '_dict')\n",
    "laser_positions = load_obj(dict_name)\n",
    "\n",
    "print(\"loading point cloud:\", file_name)\n",
    "point_cloud_xyz = load_point_cloud(path_to_gt,  mapping_files[file_name], skip_names = True)[:,:3]\n",
    "    \n",
    "print(\"loading ground detected with lambda flat zones\")\n",
    "ground_lfz = load_h5_file(path_to_ground_labeled + file_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling points using spherical prediction\n"
     ]
    }
   ],
   "source": [
    "# idx of ground and no-ground from lambda flat zones method\n",
    "no_ground_index = np.where(ground_lfz == 0)\n",
    "ground_index = np.where(ground_lfz != 0)\n",
    "\n",
    "\n",
    "centered_xyz = compute_centered_point_cloud(point_cloud_xyz)\n",
    "xyz_to_sensor = centered_xyz - laser_positions[file_name]\n",
    "\n",
    "xyz_to_sensor_no_ground = xyz_to_sensor[no_ground_index]\n",
    "\n",
    "aux_idx_proj, mapping = min_aggregation_proj(64,1024,proj_sph,xyz_to_sensor_no_ground)\n",
    "\n",
    "valid_3d_idx_in_2d = np.where(aux_idx_proj > -1)\n",
    "idx_in_3d = aux_idx_proj[valid_3d_idx_in_2d]\n",
    "\n",
    "# fill 3D labels\n",
    "print(\"Labeling points using spherical prediction\")\n",
    "labels_3d_no_ground = np.zeros_like(no_ground_index[0])\n",
    "labels_3d_no_ground[idx_in_3d] = pred[valid_3d_idx_in_2d]\n",
    "    \n",
    "\n",
    "# label \"no-ground\" points using DL model\n",
    "labels_3d_pred = np.zeros(point_cloud_xyz.shape[0])\n",
    "labels_3d_pred[no_ground_index] = labels_3d_no_ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Propagating labels to hidden ones, using knn with k = 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Propagating labels to hidden ones, using knn with k = 3\")\n",
    "\n",
    "unlabeled_points_id = np.where(labels_3d_pred == 0)[0]\n",
    "labeled_points_id = np.where(labels_3d_pred > 0)[0]\n",
    "\n",
    "X_visible, y_visible = point_cloud_xyz[labeled_points_id, :], labels_3d_pred[labeled_points_id]\n",
    "X_hidden = point_cloud_xyz[unlabeled_points_id, :]\n",
    "\n",
    "num_neighbors = 3\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=num_neighbors)\n",
    "knn.fit(X_visible, y_visible)\n",
    "y_pred_knn = knn.predict(X_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign propagated labels to non-labeled points\n",
    "labels_3d_pred[unlabeled_points_id] = y_pred_knn\n",
    "\n",
    "# label ground using lambda flat zones\n",
    "labels_3d_pred[ground_index] = 3 # label of ground in this dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_data/3d_preds/40.txt\n",
      "out_pc (4460335, 4)\n"
     ]
    }
   ],
   "source": [
    "out_pc = np.concatenate([point_cloud_xyz, labels_3d_pred.reshape(-1,1)], axis = 1)\n",
    "ppp = output_path_3d + file_name + '.txt'\n",
    "np.savetxt(ppp, out_pc)\n",
    "print(ppp)\n",
    "print(\"out_pc\", out_pc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Some observations: </b>\n",
    "\n",
    "In this notebook we performed backprojection using 2d prediction from Deep Learning model. Slightly better results are obtained using KNN from penultimate layer from DL model.\n",
    "\n",
    "Postprocessing step improves buildings and poles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_labels = load_point_cloud(path_to_gt,  mapping_files[file_name], skip_names = True)[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.93      0.79      0.86   1830101\n",
      "         2.0       0.82      0.32      0.46    356583\n",
      "         3.0       0.86      1.00      0.92   1556902\n",
      "         4.0       0.00      0.00      0.00      2751\n",
      "         5.0       0.65      0.87      0.74    710729\n",
      "\n",
      "   micro avg       0.84      0.84      0.84   4457066\n",
      "   macro avg       0.65      0.60      0.60   4457066\n",
      "weighted avg       0.85      0.84      0.83   4457066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(gt_labels[gt_labels > 0], labels_3d_pred[gt_labels > 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1453254   17549   74521     705  284072]\n",
      " [  50427  115008  139210    1034   50904]\n",
      " [   2277    1621 1552551      10     443]\n",
      " [   2665       0       0       0      86]\n",
      " [  46621    5455   41825    1390  615438]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(gt_labels[gt_labels > 0], labels_3d_pred[gt_labels > 0])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
